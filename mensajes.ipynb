{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\Luis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lo primero sera importar las librerias y estableces algunas configuraciones para\n",
    "# facilitar la lectura en pantalla\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import warnings\n",
    "import operator\n",
    "import nltk\n",
    "nltk.download('cess_esp')\n",
    "from nltk.corpus import cess_esp as cess\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import difflib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1197, 3)\n",
      "\n",
      "\n",
      "Cantidad de registros de mensajes = 1101\n",
      "\n",
      "\n",
      "Index(['Enviado/por', 'Fecha/Hora', 'Texto'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# leer los datos y cargarlos en dataframe, validando la carga al presentar informacion basica\n",
    "# del archivo\n",
    "mensajes = pd.read_json('C:/Users/Luis/Documents/Ciencia de Datos/Dataset1/mensajespd.json')\n",
    "\n",
    "print(mensajes.shape)\n",
    "\n",
    "# borramos registros duplicados desde los datos originales\n",
    "mensajes.drop_duplicates(inplace=True)\n",
    "\n",
    "#print(mensajes.head())\n",
    "print(\"\\n\")\n",
    "print(\"Cantidad de registros de mensajes = %3d\" % mensajes.shape[0])\n",
    "print(\"\\n\")\n",
    "print(mensajes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora se va a proceder a colocar en minuscula, todo el contenido de la variable \"Texto\"\n",
    "# todo a minuscula\n",
    "\n",
    "mensajes.Texto = mensajes.Texto.str.lower()\n",
    "\n",
    "# y luego eliminamos todos los acentos \n",
    "\n",
    "\n",
    "def strip_accents(text):\n",
    "    \"\"\"\n",
    "    Strip accents from input String.\n",
    "\n",
    "    :param text: The input string.\n",
    "    :type text: String.\n",
    "\n",
    "    :returns: The processed String.\n",
    "    :rtype: String.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except (TypeError, NameError): # unicode is a default on python 3 \n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = text.encode('ascii', 'ignore')\n",
    "    text = text.decode(\"utf-8\")\n",
    "    return str(text)\n",
    "\n",
    "mensajes[\"Texto\"] = mensajes[\"Texto\"].apply(lambda tx: strip_accents(tx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**el dataset requiere depuracion ya que multiples\n",
    " registros (algunos), contienen informacion de un solo mensaje, lo que distorciona la\n",
    " interpretacion de dichos mensajes\n",
    " primer paso ordenar el dataframe por \"Enviado/por\" y \"Fecha/Hora\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenamos\n",
    "mensajes.sort_values(by=[\"Enviado/por\", \"Fecha/Hora\"])\n",
    "\n",
    "# reacomodando indices\n",
    "indice = list(range(mensajes.shape[0]))\n",
    "mensajes.index = indice\n",
    "\n",
    "# convertimos a formato de fecha la columna \"Fecha/Hora\"\n",
    "mensajes[\"Fecha/Hora\"] = pd.to_datetime(mensajes[\"Fecha/Hora\"])\n",
    "\n",
    "# variable de interes tiempo en segundos (hora del dia en segundos)\n",
    "\n",
    "mensajes['ts'] = mensajes[\"Fecha/Hora\"].apply(lambda x: x.hour*60*60+x.minute*60+x.second)\n",
    "\n",
    "# el tiempo entre mensajes: tem\n",
    "# voala! funciona.. \n",
    "\n",
    "mensajes[\"tem\"] = np.zeros(mensajes.shape[0], dtype=int)\n",
    "\n",
    "mensajes[\"tem\"] = abs(mensajes[\"ts\"].diff())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# con este arreglo de indice calculado a continuacion, concatenamos \n",
    "# mensajes divididos en la fila i-1 y posterior eliminamos los (i) ndice\n",
    "# ya q seran redundantes\n",
    "# hay q tener en cuenta filtrar q mensajes a concatenar sean del mismo\n",
    "# sender y que contenido de mensajes sean distintos\n",
    "\n",
    "# cosideramos solo aquellos mensajes sucesivos que hayan sido recibidos\n",
    "# en un intervalo de tiempo menor a 10 segundos ya que en este subgrupo se encuentran\n",
    "# los mensajes divididos\n",
    "\n",
    "\n",
    "indimulmensajes = mensajes[mensajes[\"tem\"]<10].index\n",
    "\n",
    "# uniendo y borrando registros redundantes, despues de unir mensajes fragmentados.\n",
    "# Hay q recorrer el dataset de abajo hacia arriba (reverse) dado que: puede haber \n",
    "# mensajes fraccionados en mas de 2 partes y a la vez es posible borrar cada\n",
    "# registro redundante una vez que se unan.\n",
    "\n",
    "\n",
    "for i in reversed(indimulmensajes):\n",
    "    if operator.and_(mensajes[\"Enviado/por\"][i-1]==mensajes[\"Enviado/por\"][i], mensajes[\"Texto\"][i-1]!=mensajes[\"Texto\"][i]):\n",
    "        mensajes[\"Texto\"][i-1] += mensajes[\"Texto\"][i]\n",
    "        mensajes.drop(mensajes.index[i], inplace = True)\n",
    "\n",
    "\n",
    "# reacomodando indices\n",
    "indice = list(range(mensajes.shape[0]))\n",
    "mensajes.index = indice\n",
    "        \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y creamos dos nuevas variables, una que indique si \"Texto\" proviene de un suscriptor del servicio\n",
    "# de internet (0) o no (1) y otra que partiendo del contenido de \"Texto\" clasifique en mensaje,\n",
    "# lo cual se hara luego de analizar la variable \"Texto\" mas adelante\n",
    "\n",
    "# por defecto ninguno es suscriptor\n",
    "mensajes[\"es_suscriptor\"] = np.full(mensajes.shape[0], 9)\n",
    "\n",
    "# aun no se a establecido criterio para clasificar, se inicializa en 0\n",
    "mensajes[\"tipo_mensaje\"] = np.full(mensajes.shape[0], 9)\n",
    "# donde: 0->usuario reporta falla, 1->usuario solicita informacio cuota del servicio,\n",
    "# 2->todo lo demas (no suscriptores)\n",
    "\n",
    "# leer telefonos conocidos de clientes desde archivo\n",
    "# al archivo tlfclientes.csv se le agrego un caracter alfanumerico al comienzo\n",
    "# de cada registro para que pandas leyera como texto y no como numero\n",
    "\n",
    "telef_clientes = pd.read_csv('C:/Users/Luis/Documents/Ciencia de Datos/Dataset1/tlfclientes.csv')\n",
    "\n",
    "# ahora se convierte telef_clientes.telef eliminando los caracteres- al inicio y final\n",
    "telef_clientes[\"telef\"] = telef_clientes[\"telef\"].str.replace(\"-\",\"\")\n",
    "\n",
    "# y se carga a memoria como lista, ya q son pocos\n",
    "lista_telef = telef_clientes[\"telef\"].tolist()\n",
    "\n",
    "# ahora clasificamos como 0 la variable \"es_suscriptor\", si coincide lista con \n",
    "# \"Enviado/por\" del dataframe\n",
    "\n",
    "mensajes.loc[mensajes[\"Enviado/por\"].isin(lista_telef), \"es_suscriptor\"] = 0 \n",
    "\n",
    "mensajes.loc[mensajes['Enviado/por'].str.len()<11, \"es_suscriptor\" ] = 1\n",
    "\n",
    "mensajes.loc[mensajes['Enviado/por'].str.len()<11, \"tipo_mensaje\" ] = 2\n",
    "\n",
    "# guardamos todo el nuevo dataframe con datos limpios, preprocesados\n",
    "mensajes.to_pickle(\"C:/Users/Luis/Documents/Ciencia de Datos/Dataset1/mensajes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 381 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# cargamos el dataframe mensajes con datos limpios, preprocesados\n",
    "\n",
    "mensajes = pd.read_pickle(\"C:/Users/Luis/Documents/Ciencia de Datos/Dataset1/mensajes.pkl\")\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "palab_clase1 = [\"cuanto\", \"mes\", \"mensualidad\", \"interne\", \"wifi\", \"pago\"]\n",
    "\n",
    "\n",
    "# esta funcion compara las palabras clave (variantes) que deberia contener el\n",
    "# mensaje de texto para considerarlo como categoria 1 (cliente solicita info\n",
    "# acerca del cuota de servicio)\n",
    "# funciona, hay que variar el cutoff para aumentar o disminuir la presicion\n",
    "# en spyder se obtienen buenos resultados ajustando el valor a 0.7 pero\n",
    "# aca se debe ajustar a 0.8 para reducir falsos positivos\n",
    "\n",
    "def sol_cuota(text, variantes):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    palabras_en = []\n",
    "    for palabra in variantes:\n",
    "        var = difflib.get_close_matches(palabra, tokens, n=1, cutoff=0.8)\n",
    "        # aqui se puede mejorar la presicion aplicando otro filtro\n",
    "        # comparando var[0] mejor coicidencia con diccionario de \n",
    "        # palabras si se encuentra y es diferente se descarta {no sirvio :( }\n",
    "        if len(var)>0 and len(str(var[0]))>2: #and comparacion(palabra, var[0]):\n",
    "            palabras_en.append(var[0])\n",
    "    return (len(palabras_en)>=2)\n",
    "\n",
    "var1 = mensajes.index[mensajes[\"Texto\"].apply(lambda x: sol_cuota(x, palab_clase1))]\n",
    "\n",
    "# manualmente se obtuvo los mensajes que encajan con el criterio y no se\n",
    "# clasifican como tipo 1 (en tipo_mensaje)\n",
    "\n",
    "var2 = [91, 114, 150, 151, 214, 380, 419, 443, 467, 579, 678, 576, 788, 873]\n",
    "\n",
    "# a var1 le quitamos var2 y el resultado se clasifica como tipo 1 (en tipo_mensaje)\n",
    "# hay q anotar que en mensajes tipo 1 se encuentran tambien los reportes de pago\n",
    "# los cual implica que la respuesta automatica debe indicar \"ademas\" que se: \n",
    "# haga reporte por otra via o que espere para validar.\n",
    "\n",
    "var1 = set(var1)\n",
    "var2 = set(var2)\n",
    "var1 = var1-var2\n",
    "var1 = list(var1)\n",
    "\n",
    "mensajes.loc[mensajes.index[var1], \"tipo_mensaje\" ] = 1\n",
    "mensajes.loc[mensajes.index[var1], \"es_suscriptor\" ] = 0\n",
    "\n",
    "\n",
    "# aprovechamos var2 y extraemos los mensajes que son de no suscriptores en este \n",
    "# dominio\n",
    "\n",
    "var2 = list(var2)\n",
    "var2 = set(var2)\n",
    "var3 = {114, 576, 579, 788}\n",
    "var2 = var2-var3\n",
    "var2 = list(var2)\n",
    "\n",
    "\n",
    "# y var 3 contiene \"no suscriptores\"\n",
    "var3 = list(var3)\n",
    "\n",
    "mensajes.loc[mensajes.index[var2], \"es_suscriptor\" ] = 0\n",
    "mensajes.loc[mensajes.index[var3], \"es_suscriptor\" ] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posicion_palabra(palabra, tokens):\n",
    "    pos_palabra = -1\n",
    "    if len(palabra)<=3:\n",
    "        if palabra in tokens:\n",
    "            pos_palabra = tokens.index(palabra)\n",
    "    else:\n",
    "        var = difflib.get_close_matches(palabra, tokens, n=1, cutoff=0.8)\n",
    "        if len(var)>0:\n",
    "            pos_palabra = tokens.index(var[0])\n",
    "    return pos_palabra\n",
    "\n",
    "def busca_palabra(a, b, texto):\n",
    "    tokens = tokenizer.tokenize(texto)\n",
    "    pos_a = posicion_palabra(a, tokens)\n",
    "    pos_b = posicion_palabra(b, tokens)\n",
    "    \n",
    "    if pos_a < 0 or pos_b <0 : resultado = False\n",
    "    elif len(a)<=3: resultado = pos_a < pos_b\n",
    "    else: resultado = True\n",
    "    \n",
    "    return resultado\n",
    "    \n",
    "def recore_pares(conten_par, texto):\n",
    "    for conte in conten_par:\n",
    "        a = conte[0]\n",
    "        b = conte[1]\n",
    "        return busca_palabra(a, b, texto)\n",
    "    \n",
    "\n",
    "palab_clave1 = ['no', 'sin', 'falla', 'caida']\n",
    "\n",
    "palab_clave2 = ['internet', 'conexion', 'red', 'servicio', 'wifi', 'senal']\n",
    "\n",
    "# formamos pares de palabras claves\n",
    "palab_clave = []\n",
    "\n",
    "for pal1 in palab_clave1: \n",
    "    for pal2 in palab_clave2: \n",
    "        palab_clave.append([pal1, pal2])\n",
    "\n",
    "var1 = mensajes.index[mensajes[\"Texto\"].apply(lambda x: recore_pares(palab_clave, x))]\n",
    "\n",
    "var2 = [57, 554]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enviado/por      156\n",
      "Fecha/Hora       156\n",
      "Texto            156\n",
      "ts               156\n",
      "tem              156\n",
      "es_suscriptor    156\n",
      "tipo_mensaje     156\n",
      "dtype: int64\n",
      "     Enviado/por          Fecha/Hora  \\\n",
      "57   04160795035 2018-05-09 20:11:26   \n",
      "554  04147505858 2018-03-11 14:10:55   \n",
      "\n",
      "                                                                                                                                     Texto  \\\n",
      "57   buenas noches! sr luis ya le transferimos del provincial el numero es 76073878. esta listo p q manana no nos corte el internet          \n",
      "554  senor luis usted por casualidad no podra colocar el internet horita y le hago una transferencia. y disculpe cuanto es la mensualidad?   \n",
      "\n",
      "        ts     tem  es_suscriptor  tipo_mensaje  \n",
      "57   72686  8102.0  0              9             \n",
      "554  51055  4782.0  0              1             \n"
     ]
    }
   ],
   "source": [
    "var2 = [57, 554]\n",
    "print(mensajes.iloc[mensajes.index[var1]].count())\n",
    "\n",
    "print(mensajes.iloc[mensajes.index[var2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**es_suscriptor: esta variable toma valor 0 si el contenido de \"Texto\" proviene de un\n",
    "cliente de la red comunitaria, y 1 en caso contrario. Pero Â¿Como se determina si el \n",
    "mensaje proviene o no de un suscriptor?**\n",
    "**a vuelo de pajaro podemos decir que:**\n",
    "\n",
    "**1- Si hacemos query de \"Enviado/por\" en la base de datos de cliente y aparece en esta\n",
    "definitivamente el mensaje fue enviado por un suscriptor, es el caso mas sencillo**\n",
    "\n",
    "**2- Que pasa si el query no devuelve datos, quiere decir que no se encuentra registrado\n",
    "pero esto no quiere decir que el mensaje no provenga de un cliente, sino que tal vez\n",
    "este usando otro dispositivo no registrado en la base de datos, de alli que surga la necesidad\n",
    "de analizar el contenido para establecer el valor de la variable es_suscriptor.\n",
    "en este apartado se puede inferir que tal vez el usuario se identifique con su nombre\n",
    "dentro del contenido del mensaje o tal vez no, en caso de que si, la solucion pasaria algo\n",
    "similar a 1, en caso contrario se necesitara establecer mas precision en cuanto al contenido\n",
    "de \"Texto\" y hasta sera necesario interpretar varios mensajes simultaneamente del mismo \n",
    "Enviado/por\" en un tiempo-estipulado e interactuar con el remintente para clasificarlo.**\n",
    "\n",
    "**3- Otro aspecto que pareciera ser prometedor es la frecuencia de origen de sms, obtenida de \n",
    "la variable \"Enviado/por\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Bien, repasando de nuevo, un mensaje se considera que proviene de un suscriptor en estos \n",
    "casos:**\n",
    "\n",
    "**1- su origen plasmado en la variable \"Enviado/por\", resuelto anteriormente**\n",
    "\n",
    "**2- contenga frases asociadas con el servicio de internet, en especial las siguientes\n",
    "son trascendentes: \"no hay conexion\", \"no hay internet\", \"cuanto es la mensualidad\"**\n",
    "\n",
    "**3- tomar en cuenta comodin por error ortografico comun \"interne\" y otros\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
